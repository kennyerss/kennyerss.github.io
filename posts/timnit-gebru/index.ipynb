{
 "cells": [
  {
   "cell_type": "raw",
   "id": "38b757c4-bc3e-4e4d-a180-f7e19630f814",
   "metadata": {},
   "source": [
    "---\n",
    "title: Learning from Timnit Gebru\n",
    "author: Kent Canonigo\n",
    "date: '2023-04-19'\n",
    "image: \"cover.png\"\n",
    "description: \"In this blog post, I talk about my learnings from Dr. Timnit Gebru's talk on 'Eugenics and the Promise of Utopia through Artificial General Intelligence'.\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e249b1-5d04-46f7-9694-57302540ec83",
   "metadata": {},
   "source": [
    "## Introduction: Dr. Timnit Gebru's Talk at Middlebury College"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7336879-20d5-496d-a97b-268eb8b0de02",
   "metadata": {},
   "source": [
    "On Tuesday, April 24th, [Dr. Timnit Gebru](https://en.wikipedia.org/wiki/Timnit_Gebru) will give a talk on the \"Eugenics and the Promise of Utopia through Artificial Intelligence\" at Middlebury College. Dr. Gebru, a renowned computer scientist who specializes in data mining and algorithmic bias, has long advised for the ethical uses of AI. In her short tenure in Google in 2018, she co-led a team focused on ethical artificial intelligence. During this time, Dr. Gebru warned of the dangers of a large language model (being the basis of the Google search engine) through her findings in this [paper](https://dl.acm.org/doi/pdf/10.1145/3442188.3445922). However, she faced pushback from higher Google executives to withdraw her paper and remove her and other Google team members' names from the list of co-authors. What spurred from this event was a sequence of back-and-forth arguments with Dr. Gebru paving the way for ethical uses of AI — particularly in her and [Joy Buolamwini](https://en.wikipedia.org/wiki/Joy_Buolamwini)'s groundbreaking study of [Gender Shades](http://gendershades.org) which criticized facial recognition technologies' flaws in its inability to recognize Black women. Needless to say, the 2020 protests during the Black Lives Matter movement further emphasized the harms and dangers of facial recognition technology against vulnerable communities of color.\n",
    "\n",
    "Dr. Gebru's voice in the ethics of AI poses a need to break down the systemic structures that allow AI to exploit communities of color. How long must the development of AI go unchecked as linguistic boundaries regarding the transparency of AI technology blur the rights and wrongs? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cf2ccc-5db2-43f0-aa19-f6727288cb9a",
   "metadata": {},
   "source": [
    "## Tutorial on Fairness, Accountability, Transparency, and Ethics (FATE) in Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71703976-f705-4089-834a-27d24cbc4a79",
   "metadata": {},
   "source": [
    "In her talk in the 2020 conference on Computer Vision and Pattern Recognition, Dr. Gebru brings up a quote by Mimi Onuoha to emphasize that it is \"imperative to remember on both sides we have human beings\" within data sets involving people as subjects or objects. I found this quote to be effective as later on, Dr. Gebru brings up an anecdote given by Seeta Pena Gangadharan, as they reflect on the *abstraction* of human beings into mathematical equations; this anecdote was important in separating human subjects rather than a means of gathering statistics and mathematical computations. As researchers abstract the reality that people live in into simple data, they fail to recognize the importance of acknowledging the social and power structures that influence and empower algorithmic biases. Dr. Gebru provides several studies such as the Gender Shades project, a wedding classification, and gender classification focused on gender norms.\n",
    "\n",
    "Additionally, the datasets on which models are created may be biased which poses important questions about class imbalance. While there is an inherent need to *diversify* datasets, there are fundamental questions to how data should be ethically obtained. Dr. Gebru observes that companies have crossed the boundaries of data collection which infringes people's civil liberties online data being retrieved and used for AI models (e.g. facial recognition) without their consent. Federal regulations must be up to date to check the powers of large companies on infringing the consent and privacy of users. Additionally, it's important that the *design* of AI models are constructed inclusively with collaboration of communities of color. \n",
    "\n",
    "**tldr; Computer vision as it's used today transforms the intent of the designer to perpetuate systems of oppression we live in today, furthering the harms of those historically marginalized and excluded.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69294b17-65cb-4a90-9250-87ad5f5e8eaa",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d8eeb8-f512-4e35-ac79-ed55790a88b3",
   "metadata": {},
   "source": [
    "Here is my question I would like to ask Dr. Gebru: \n",
    "\n",
    "**What role *should* the designer play in the way AI processes are created, maintained, and commercialized?** This question is in the context of design — specifically the design of AI and its role in perpetuating systems that enhance racial and gender biases. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-0451]",
   "language": "python",
   "name": "conda-env-ml-0451-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
